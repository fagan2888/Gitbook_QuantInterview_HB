#### Linear Regression

* proof MLE Estimate &lt;=&gt; RSS Min Estimate
  * use p.d.f of $$\epsilon$$ on beta
* Derive beta
  * Single variable: min RSS = $$\sum (y_i - (\beta_1 x_i + \beta_0)$$
  * Muti-variable $$\mathbf{w^*} = (\mathbf{X^T X})^{-1} \mathbf{X^T y} $$
* Loss Function
  * Blue
  * Huber Loss Function

#### Logistic Regression

* Intuition - Why do we have it
  * different contribution of large/small data
    * exponential family and penalize
  * odds, log odds
* Loss function derive parameter estimation
  * MLE - y is bernoulli function \(entropy loss\)
* Gradient Descent
  * entropy loss
  * MSE



